{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook accompagnies Figure 4 of the paper:\n",
    "#### \"A Review of the Gumbel-max Trick and its Extensions for Discrete Stochasticity in Machine Learning\" (https://arxiv.org/abs/2110.01515)\n",
    "\n",
    "This notebook can be used to gain insights in the relations between Gumbel-max and Gumbel-softmax samples, generated from unnormalized logits or normalized probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some helper functions and libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def softmax(x, temperature=1.):\n",
    "    \"Numerically stable implementation of tempered softmax\"\n",
    "    x_max = x.max()\n",
    "    y = np.exp((x - x_max)/temperature)\n",
    "    return y / y.sum()\n",
    "\n",
    "def log_softmax(x):\n",
    "    \"Numerically stable implementation of log-softmax\"\n",
    "    x_max = x.max()\n",
    "    logsumexp = np.log(np.exp(x - x_max).sum())\n",
    "    return x - x_max - logsumexp\n",
    "\n",
    "def one_hot(idx, nr_classes):\n",
    "    \"Converts an index to a one-hot vector of length nr_classes\"\n",
    "    return np.eye(nr_classes)[int(idx)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Indicate the number of classes, the Boltzmann and Gumbel-softmax temperature and the Gumbel noise scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_classes = 4\n",
    "\n",
    "boltzmann_temp = 1. #boltzmann temperature T\n",
    "GS_temp = 1. # Gumbel-softmax temperature lambda\n",
    "beta = 1. # Gumbel noise scale beta\n",
    "\n",
    "# Generate random unnormalized logits a\n",
    "a = np.random.normal(size=(nr_classes,))\n",
    "\n",
    "# Draw Gumbels\n",
    "gumbels = -np.log(-np.log(np.random.uniform(size=(nr_classes,))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute (un)normalized logits via various paths and confirm that it results in the same output\n",
    "log_pi_via_pi = np.log(softmax(a/boltzmann_temp))\n",
    "log_pi_via_a = log_softmax(a/boltzmann_temp)\n",
    "\n",
    "np.allclose(\n",
    "    log_pi_via_pi, \n",
    "    log_pi_via_a\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Gumbel-Softmax sample via various paths and confirm that it results in the same output\n",
    "log_pi_via_pi_perturbed = log_pi_via_pi + gumbels\n",
    "unnormalized_log_perturbed = a/boltzmann_temp + gumbels\n",
    "\n",
    "np.allclose(\n",
    "    softmax(log_pi_via_pi_perturbed, GS_temp), \n",
    "    softmax(unnormalized_log_perturbed, GS_temp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compute hard sample via various paths and confirm that it results in the same output\n",
    "print(np.allclose( \n",
    "    np.argmax(log_pi_via_pi_perturbed), \n",
    "    np.argmax(softmax(log_pi_via_pi_perturbed, GS_temp)), \n",
    "    )\n",
    "     )\n",
    "\n",
    "print(np.allclose(\n",
    "    np.argmax(unnormalized_log_perturbed), \n",
    "    np.argmax(softmax(unnormalized_log_perturbed, GS_temp)) \n",
    "    )\n",
    ")\n",
    "\n",
    "print(np.allclose(\n",
    "    np.argmax(log_pi_via_pi_perturbed),\n",
    "    np.argmax(unnormalized_log_perturbed), \n",
    "    )\n",
    ")\n",
    "\n",
    "gumbel_max_sample = np.argmax(log_pi_via_pi_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compute Gumbel-(soft)max sample via Gumbel noise scaling instead of Boltzmann temperature and confirm that it results in the same output\n",
    "print(np.allclose(\n",
    "    np.argmax(softmax(a + beta*gumbels, GS_temp)),\n",
    "    np.argmax(a + beta*gumbels),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(np.allclose(\n",
    "    np.argmax(a + beta*gumbels),\n",
    "    gumbel_max_sample # Compare to earlier computed argmax output\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Move the GS temperature towards zero and confirm that it results in the same output, as taking the one_hot operation of the argmax outputs\n",
    "GS_temp = 1e-8\n",
    "print(np.allclose(\n",
    "    softmax(a + beta*gumbels, GS_temp),\n",
    "    softmax(unnormalized_log_perturbed, GS_temp),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(np.allclose(\n",
    "    softmax(a + beta*gumbels, GS_temp),\n",
    "    one_hot(gumbel_max_sample, nr_classes)\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
